import OpenAI from "openai";
import { IAIAnalysisPort, MessageData, MessageAnalysis } from '../../domain/ports/IAIAnalysisPort';

// the newest OpenAI model is "gpt-5" which was released August 7, 2025. do not change this unless explicitly requested by the user

export interface AIPromptConfig {
  id: string;
  tenantId: string;
  name: string;
  description: string;
  systemPrompt: string;
  userPromptTemplate: string;
  enabled: boolean;
  category: 'analysis' | 'response' | 'classification';
  createdAt: Date;
  updatedAt: Date;
}

export class AIAnalysisService implements IAIAnalysisPort {
  private openai: OpenAI;
  private defaultPrompts: Map<string, AIPromptConfig> = new Map();

  constructor() {
    this.openai = new OpenAI({ 
      apiKey: process.env.OPENAI_API_KEY 
    });
    this.initializeDefaultPrompts();
  }

  private initializeDefaultPrompts(): void {
    // Prompt padr√£o para an√°lise de mensagens
    const analysisPrompt: AIPromptConfig = {
      id: 'default-analysis',
      tenantId: 'system',
      name: 'An√°lise Padr√£o de Mensagem',
      description: 'Analisa mensagens recebidas para classificar inten√ß√£o, sentimento e urg√™ncia',
      systemPrompt: `Voc√™ √© um especialista em an√°lise de atendimento ao cliente. Analise a mensagem fornecida e retorne uma an√°lise estruturada em JSON.

Considere:
- A inten√ß√£o do usu√°rio (reclama√ß√£o, pergunta, solicita√ß√£o, emerg√™ncia, elogio, outros)
- O sentimento (positivo, negativo, neutro)
- O n√≠vel de urg√™ncia (baixo, m√©dio, alto, cr√≠tico)
- A categoria do assunto
- Palavras-chave importantes
- Se deve criar um ticket automaticamente
- A√ß√µes sugeridas para o atendimento
- Um resumo conciso da mensagem

Responda SEMPRE em formato JSON v√°lido.`,
      userPromptTemplate: `Analise esta mensagem de atendimento:

CANAL: {channel}
REMETENTE: {sender}
ASSUNTO: {subject}
CONTE√öDO: {content}
DATA: {timestamp}

Forne√ßa a an√°lise no seguinte formato JSON:
{
  "intent": "complaint|question|request|emergency|compliment|other",
  "sentiment": "positive|negative|neutral", 
  "urgency": "low|medium|high|critical",
  "category": "categoria do assunto",
  "keywords": ["palavra1", "palavra2", "palavra3"],
  "suggestedActions": ["a√ß√£o1", "a√ß√£o2"],
  "confidence": 0.85,
  "summary": "resumo conciso da mensagem",
  "shouldCreateTicket": true|false,
  "suggestedResponse": "resposta sugerida (opcional)"
}`,
      enabled: true,
      category: 'analysis',
      createdAt: new Date(),
      updatedAt: new Date()
    };

    this.defaultPrompts.set('analysis', analysisPrompt);

    // Prompt para gera√ß√£o de respostas autom√°ticas
    const responsePrompt: AIPromptConfig = {
      id: 'default-response',
      tenantId: 'system', 
      name: 'Gera√ß√£o de Resposta Autom√°tica',
      description: 'Gera respostas contextuais para mensagens de clientes',
      systemPrompt: `Voc√™ √© um assistente de atendimento ao cliente profissional e emp√°tico. 

Gere respostas que sejam:
- Cordiais e profissionais
- Emp√°ticas ao contexto do cliente
- Claras e objetivas
- Adequadas ao canal de comunica√ß√£o
- Em portugu√™s brasileiro

Evite:
- Promessas que n√£o podem ser cumpridas
- Linguagem muito t√©cnica
- Respostas gen√©ricas demais`,
      userPromptTemplate: `Com base na an√°lise da mensagem, gere uma resposta adequada:

AN√ÅLISE: {analysis}
MENSAGEM ORIGINAL: {originalMessage}
CANAL: {channel}
CONTEXTO ADICIONAL: {context}

Gere uma resposta profissional e emp√°tica em portugu√™s.`,
      enabled: true,
      category: 'response',
      createdAt: new Date(),
      updatedAt: new Date()
    };

    this.defaultPrompts.set('response', responsePrompt);
  }

  async analyzeMessage(messageData: MessageData, customPrompt?: AIPromptConfig): Promise<MessageAnalysis> {
    try {
      const prompt = customPrompt || this.defaultPrompts.get('analysis')!;
      
      // Substituir vari√°veis no template do prompt
      const userPrompt = prompt.userPromptTemplate
        .replace('{channel}', messageData.channel || 'Desconhecido')
        .replace('{sender}', messageData.sender || 'An√¥nimo')
        .replace('{subject}', messageData.subject || 'Sem assunto')
        .replace('{content}', messageData.content)
        .replace('{timestamp}', messageData.timestamp || new Date().toISOString());

      console.log(`ü§ñ [AI-ANALYSIS] Analyzing message from ${messageData.sender} via ${messageData.channel}`);

      const response = await this.openai.chat.completions.create({
        model: "gpt-5",
        messages: [
          {
            role: "system",
            content: prompt.systemPrompt
          },
          {
            role: "user", 
            content: userPrompt
          }
        ],
        response_format: { type: "json_object" }
      });

      const analysis = JSON.parse(response.choices[0].message.content || '{}');
      
      // Validar e normalizar a resposta
      const normalizedAnalysis: MessageAnalysis = {
        intent: analysis.intent || 'other',
        sentiment: analysis.sentiment || 'neutral',
        urgency: analysis.urgency || 'medium',
        category: analysis.category || 'Geral',
        keywords: Array.isArray(analysis.keywords) ? analysis.keywords : [],
        confidence: typeof analysis.confidence === 'number' ? analysis.confidence : 0.5,
        summary: analysis.summary || 'Mensagem recebida',
        suggestedResponse: analysis.suggestedResponse || undefined,
        requiresHumanAttention: Boolean(analysis.shouldCreateTicket || analysis.urgency === 'critical' || analysis.intent === 'emergency'),
        language: analysis.language || 'pt-BR'
      };

      console.log(`‚úÖ [AI-ANALYSIS] Analysis completed - Intent: ${normalizedAnalysis.intent}, Urgency: ${normalizedAnalysis.urgency}`);

      return normalizedAnalysis;
    } catch (error) {
      console.error('‚ùå [AI-ANALYSIS] Error analyzing message:', error);
      
      // Retorna an√°lise b√°sica em caso de erro
      return {
        intent: 'other',
        sentiment: 'neutral',
        urgency: 'medium',
        category: 'Geral',
        keywords: [],
        confidence: 0,
        summary: 'Erro na an√°lise autom√°tica',
        suggestedResponse: undefined,
        requiresHumanAttention: true,
        language: 'pt-BR'
      };
    }
  }

  async generateResponse(analysisData: MessageAnalysis, originalMessage: string, context?: any, customPrompt?: AIPromptConfig): Promise<string> {
    try {
      const prompt = customPrompt || this.defaultPrompts.get('response')!;
      
      // Enhanced system prompt based on context
      let enhancedSystemPrompt = prompt.systemPrompt;
      
      if (context?.customInstructions) {
        enhancedSystemPrompt += `\n\nINSTRU√á√ïES ESPEC√çFICAS: ${context.customInstructions}`;
      }

      if (context?.tone) {
        const toneInstructions = {
          professional: 'Mantenha um tom profissional e respeitoso.',
          friendly: 'Use um tom amig√°vel e caloroso, mas ainda profissional.',
          technical: 'Use linguagem t√©cnica precisa, mas acess√≠vel.',
          sales: 'Foque em benef√≠cios e valor, com call-to-action quando apropriado.',
          empathetic: 'Demonstre empatia genu√≠na e compreens√£o.',
          formal: 'Use linguagem formal e protocolar.'
        };
        enhancedSystemPrompt += `\n\nTOM: ${toneInstructions[context.tone as keyof typeof toneInstructions] || toneInstructions.professional}`;
      }

      if (context?.language) {
        const languageInstructions = {
          'pt-BR': 'Responda em portugu√™s brasileiro.',
          'en-US': 'Respond in American English.',
          'es-ES': 'Responde en espa√±ol.',
          'fr-FR': 'R√©pondez en fran√ßais.'
        };
        enhancedSystemPrompt += `\n\nIDIOMA: ${languageInstructions[context.language as keyof typeof languageInstructions] || languageInstructions['pt-BR']}`;
      }

      const userPrompt = prompt.userPromptTemplate
        .replace('{analysis}', JSON.stringify(analysisData, null, 2))
        .replace('{originalMessage}', originalMessage)
        .replace('{channel}', context?.channel || 'Desconhecido')
        .replace('{context}', context ? JSON.stringify(context, null, 2) : 'Nenhum contexto adicional');

      console.log(`ü§ñ [AI-RESPONSE] Generating response for ${analysisData.intent} message with tone: ${context?.tone || 'default'}`);

      const response = await this.openai.chat.completions.create({
        model: "gpt-5",
        messages: [
          {
            role: "system",
            content: enhancedSystemPrompt
          },
          {
            role: "user",
            content: userPrompt
          }
        ],
        max_tokens: context?.maxResponseLength ? Math.min(context.maxResponseLength * 2, 2000) : 1000,
        temperature: context?.tone === 'technical' ? 0.3 : context?.tone === 'sales' ? 0.7 : 0.5
      });

      let generatedResponse = response.choices[0].message.content || 'Obrigado pelo seu contato. Nossa equipe analisar√° sua mensagem.';

      // Apply length limit if specified
      if (context?.maxResponseLength && generatedResponse.length > context.maxResponseLength) {
        generatedResponse = generatedResponse.substring(0, context.maxResponseLength - 3) + '...';
      }

      // Include original message if requested
      if (context?.includeOriginalMessage) {
        generatedResponse = `Referente √† sua mensagem: "${originalMessage}"\n\n${generatedResponse}`;
      }

      console.log(`‚úÖ [AI-RESPONSE] Response generated successfully (${generatedResponse.length} chars)`);

      return generatedResponse;
    } catch (error) {
      console.error('‚ùå [AI-RESPONSE] Error generating response:', error);
      return 'Obrigado pelo seu contato. Nossa equipe analisar√° sua mensagem e retornar√° o mais breve poss√≠vel.';
    }
  }

  async classifyIntent(text: string): Promise<{intent: string, confidence: number}> {
    try {
      const response = await this.openai.chat.completions.create({
        model: "gpt-5",
        messages: [
          {
            role: "system",
            content: "Classifique a inten√ß√£o desta mensagem em uma das categorias: complaint, question, request, emergency, compliment, other. Responda em JSON com intent e confidence."
          },
          {
            role: "user",
            content: text
          }
        ],
        response_format: { type: "json_object" }
      });

      const result = JSON.parse(response.choices[0].message.content || '{"intent": "other", "confidence": 0.5}');
      return {
        intent: result.intent || 'other',
        confidence: typeof result.confidence === 'number' ? result.confidence : 0.5
      };
    } catch (error) {
      console.error('‚ùå [AI-CLASSIFICATION] Error classifying intent:', error);
      return { intent: 'other', confidence: 0 };
    }
  }

  getDefaultPrompt(type: 'analysis' | 'response'): AIPromptConfig | undefined {
    return this.defaultPrompts.get(type);
  }

  setCustomPrompt(tenantId: string, promptConfig: AIPromptConfig): void {
    const key = `${tenantId}-${promptConfig.category}`;
    this.defaultPrompts.set(key, promptConfig);
    console.log(`‚úÖ [AI-PROMPTS] Custom prompt configured for tenant ${tenantId}: ${promptConfig.name}`);
  }

  getCustomPrompt(tenantId: string, category: string): AIPromptConfig | undefined {
    return this.defaultPrompts.get(`${tenantId}-${category}`);
  }
}